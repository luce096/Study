# NginX (엔진 엑스)

# Nginx 를 알기 전에 웹서버란?
- HTTP 프로토콜을 이용하여 html 데이터를 클라이언트에게 제공해주는 서버이다. HTTP 프로토콜이란 OSI 7 계층인 application layer에 위치한 프로토콜로서 브라우저(클라이언트)와 서버 사이에 정보를 주고 받기 위한 프로토콜로 사용된다. 즉, 웹(사이트)를 이용한다면, 사이트로 들어갈 때, 어떤 방식을 사용해서, 서버는 어떻게 응답할 것인지를 정해놓은 약속이다.
- 웹서버로는 Nginx 와 Apache 등이 있다.


# 개요
- 가벼우면서도 강력한 프로그램을 목표로 러시아에서 개발되어 미국에서 운영 중인 오픈 소스 웹 서버 프로그램이다.
- '엔진엑스'라고 읽는다. HTTP와 리버스 프록시, IMAP/POP3 등의 서버 구동이 가능하다. Java 서블릿은 대개 Apache의 Tomcat을 연동해서 구동하고,
- PHP의 경우 PHP-FPM(FastCGI Process Manager)을 연동해서 구동한다.
- 이 웹 서버 소프트웨어는 웹 어플리케이션을 안정적으로 제공할 수 있도록 도와주는 역할을 한다.
- 웹 서버 소프트웨어에는 NginX 와도 많이 비교되며, 잘 알려져있는 Apache도 있다. Apache와 NginX의 차이는 클라이언트의 요청을 처리하는 동적 벙식이라고 한다.
- Apahe : 스레드/프로세스 기반으로 하는 방식으로 요청을 처리하는데, 요청 하나당 스레드 하나가 처리하는 구조로 사용자가 많아지면 CPU와 메모리 사용이 증가해서 성능이 저하될 수 있다고 한다.
- NginX : 비동기 이벤트 기반으로 하는 방식으로 처리하는데 요청이 들어오면 어떤 동작을 해야하는지만 알려주고 다음 요청을 처리하는 방식으로 진행된다고 하는데, 흐름이 끊기지 않고 응답이 빠르다고 한다. 이에 맞게 NginX는 공식 홈페이지를 보면 가볍고 빠른 성능을 추구한다고 나와있다.


NginX가 웹 어플리케이션을 안정적으로 제공할 수 있도록 도와주는 몇 가지 기능에 대해서 알아보자.

# NginX 등장배경
문제점 발생
- 동시 접속자 폭발
- 네트워크 소켓을 통해 최대로 커버 가능한 동시 접속자의 작업수는 1만개였다. 이때 당시는 사용자 수 = 프로세스 개수(혹은 쓰레드 개수)로 서버 인프라가 설계되어 CPU, 메모리 등 자원들이 사용되었다.

문제점 해결
- 동시 접속에 특화된 Nginx를 쓰자!
- 효율적인 서버 자원(CPU, 메모리 등) 사용 
- Nginx 개요
   세계에서 가장 많이 사용하고 있는 웹서버이다. (웹서버의 TOP2 아파치와 엔진엑스)
  - 웹 서버의 역할 
    - 정적 파일을 처리하는 HTTP 서버
    -  클라이언트가 정적 파일(HTTP, CSS, Javascript, 이미지)만 요청했다면 웹 서버가 직접 응답할 수 있다.




# 프록시
- ‘대리’라는 의미로, 네트워크 기술에서는 프로토콜에 있어서 대리 응답 등에서 친숙한 개념입니다. 보안 분야에서는 주로 보안상의 이유로 직접 통시할 수 없는 두 점 사이에서 통신을 할 경우 그 사이에 있어서 중게기로서 대리로 통신을 수행하는 기능을 가리켜 ‘프록시’, 그 중계 기능을 하는 것을 프록시 서버라고 부릅니다.
  프록시 서버의 특징
- 프록시 서버는 클라이언트 입장과 서버의 입장에서 볼 때 서로 상반되는 역할을 하는 것처럼 인식됩니다. 다시 말해서, 클라이언트 호스트에서의 입장에서 보나면 프록시 서버는 마치 원격 서버처럼 동작하는 것이고, 원격 서버에서의 입장에서 본다면 마치 클라이언트처럼 동작하는 것입니다.
- 단순히 보안상의 이유만으로 설치하는 것은 아닙니다. 물론 보안상의 목적으로 설치하는 경우가 많겠지만, 그렇다고 그렇게 단순하게 볼 수만은 없을 것입니다.
- 우선 프록시 서버는 프록시 서버에 요청된 내용들을 캐시를 이용하여 저장해 둡니다. 이렇게 캐시를 해 두고 난 후에, **캐시 안에 있는 정보를 요구하는 요청에 대해서는 원격 서버에 접속하여 데이터를 가져올 필요가 없게 됨으로써 전송 시간을 절약**할 수 있게 됨과 동시에 **불필요하게 외부와의 연결을 하지 않아도 된다**는 장점을 갖게 됩니다. 또한 **외부와의 트래픽을 줄이게 됨으로써 네트워크 병목 현상을 방지하는 효과**도 얻을 수 있게 됩니다.

# 로드 밸런싱(load balancing)
- 로드 밸런서는 직역하면 부하 분산으로, 서버에 가해지는 부하를 분산해주는 역할을 하는 것이다.
- 이용자가 많아서 발생하는 요청이 많을 때, 하나의 서버에서 이를 모두 처리하는 것이 아니라 여러
  대의 서버를 이용하여 요청을 처리하게 한다.
- 이때 서버의 로드율과 부하량을 고려하여 적절하개 서버들에게 분산처리 하는 것을 로드 밸런싱이라고 한다.
- 하나의 서버가 멈추더라도 서비스 중단 없이 다른 서버가 서비스를 게속 유지할 수 인는 무중단 배포가 가능하다는 장점이 있다.


# 프록시 서버의 종류

Forward 프록시
- 이것은 프록시 서버를 '클라이언트 호스트들과 접근하고자 하는 원격 리소스의 사이'에 위치시키는 것입니다.
- 이 프록시 서버는 원격 서버로부터 요청된 리소스를 가져와서 요청한 사용자에게 돌려주는 역할을 수행하며, 만일 캐시에 데이터가 남아 있다면 다음 요청시 캐시된 데이터로부터 제공해 주게 됩니다. 
- 이 서버는 전형적으로 로컬 디스크에 데이터를 저장하며, 클라이언트 호스트들은 사용중인 웹 브라우저를 이용하여 프록시 서버 사용 설정을 해야 하므로 프록시 서버를 사용하고 있다는 것을 인식할 수 있을 것입니다.
- 이 방식은 대역폭 사용을 감소시킬 수 있다는 것과 접근 정책 구현에 있어 다루기 쉬우면서도 비용이 저렴하다는 장점을 갖습니다. 또한 사용자의 정해진 사이트만 연결할수 있는 등 웹 사용 환경을 제한할 수 있으므로 기업 환경등에서 많이 사용합니다.
  쉽게 설명하면 중계 기능을 하는 서버이다.
- 클라이언트가 서버를 호출할 대 직접 서버에 접근 하는 것이 아니라 리버스 프록시 서버를 호출하게 되고, 리버스 프록시 서버가 서버에게 요청을 하고 응답을 받아 클라이언트에 전달을 한다.
- 클라이언트는 리버스 프록시 서버를 호출하기 때문에 실제 서버의 IP를 감출 수 있고, 이를 통해 보안을 높일 수 있다는 장점이 있다.

Reverse 프록시
- 이것은 프록시 서버를 '인터넷 리소스 또는 인트라넷 리소스 앞'에 위치시키는 방식입니다. 
- 이 방식을 사용하면 클라이언트들이 프록시 서버에 연결되었다는 것을 알지 못하게 되며, 마치 최종 사용자가 요청 리소스에 직접 접근하는 것과 같이 느끼게 됩니다.
-  내부 서버가 직접 서비스를 제공해도 되지만 이렇게 구성하는 이유는 보안 때문입니다.
-  보통 기업의 네트워크 환경은 DMZ 라고 하는 내부 네트워크와 외부 네트워크 사이에 위치하는 구간이 존재하며 이 구간에는 메일 서버, 웹 서버, FTP 서버등 외부 서비스를 제공하는 서버가 위치하게 됩니다. 
- 사는 서비스를 자바로 구현해서 WAS 를 DMZ 에 놓고 서비스해도 되지만 WAS 는 보통 DB 서버와 연결되므로 WAS 가 최전방에 있으면 WAS 가 털릴 경우 DB 서버까지 같이 털리는 심각한 문제가 발생할 수 있습니다.
- 이 때문에 리버스 프록시 서버를 두고 실제 서비스 서버는 내부망에 위치시키고 프록시 서버만 내부에 있는 서비스 서버와 통신해서 결과를 클라이언트에게 제공하는 방식으로 서비스를 하게 됩니다. 
- 특히 리눅스 환경에서 리버스 프록시로 아파치 웹 서버를 사용한다면 SELinux 를 켜 놓으면 SELinux 의 기본 정책이 웹 서버는 톰캣의 8080, 8009 포트만 접근 할 수 있으므로 아파치 웹 서버가 해킹당해도 웹 서버 권한으로는 내부망으로 연결이 불가합니다.
-  또한 리버스 프록시 방식은 각 요청에 대한 데이터가 캐시되기 때문에 프록시 서버는 실제 서버들을 위한 부하조절 기능을 가질 수 있습니다.